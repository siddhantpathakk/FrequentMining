{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = './data/dummy_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global freq_itemsets, support, basket_count\n",
    "\n",
    "freq_itemsets = []\n",
    "support = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'apple'),\n",
       " ('1', 'carrot'),\n",
       " ('1', 'durian'),\n",
       " ('2', 'banana'),\n",
       " ('2', 'carrot'),\n",
       " ('2', 'edamame'),\n",
       " ('3', 'apple'),\n",
       " ('3', 'banana'),\n",
       " ('3', 'carrot'),\n",
       " ('3', 'edamame'),\n",
       " ('4', 'banana'),\n",
       " ('4', 'edamame')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "with open(input_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tid = line.split(',')[0]\n",
    "        items = line.replace('\\n','').split(',')[1:]\n",
    "        if len(items)>1:\n",
    "            assert NotImplementedError\n",
    "        data.append(tuple([tid, items[0]]))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'apple', 'carrot', 'durian'},\n",
       " '2': {'banana', 'carrot', 'edamame'},\n",
       " '3': {'apple', 'banana', 'carrot', 'edamame'},\n",
       " '4': {'banana', 'edamame'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "for item in data:\n",
    "    if item[0] not in data_dict.keys():\n",
    "        data_dict[item[0]] = set()\n",
    "        data_dict[item[0]].add(item[1])\n",
    "    else:\n",
    "        data_dict[item[0]].add(item[1])\n",
    "        \n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple', 'durian', 'carrot'}\n",
      "{'banana', 'carrot', 'edamame'}\n",
      "{'banana', 'apple', 'carrot', 'edamame'}\n",
      "{'banana', 'edamame'}\n"
     ]
    }
   ],
   "source": [
    "basket = list(data_dict.values())\n",
    "basket_count = len(basket)\n",
    "\n",
    "for txn in basket:\n",
    "    print(txn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_dict(items, support_value):\n",
    "    item_counts = {}\n",
    "    for item in items:\n",
    "        if item not in item_counts.keys():\n",
    "            item_counts[item] = 1\n",
    "        else:\n",
    "            if item_counts[item] < support_value:\n",
    "                item_counts[item] = item_counts[item] + 1\n",
    "    return item_counts\n",
    "\n",
    "def create_count_dict_tuple(chunk, support_value, candidate_tuples):\n",
    "    tuple_counts = {}\n",
    "    for basket in chunk:\n",
    "        for candidate in candidate_tuples:\n",
    "            if set(candidate).issubset(basket):\n",
    "                if candidate in tuple_counts and tuple_counts[candidate] < support_value:\n",
    "                    tuple_counts[candidate] += 1\n",
    "                elif candidate not in tuple_counts:\n",
    "                    tuple_counts[candidate] = 1\n",
    "    return tuple_counts\n",
    "\n",
    "def filter_by_support(count_dict, support_value, is_tuple):\n",
    "    frequent_candidates = []\n",
    "    for candidate, count in count_dict.items():\n",
    "        if count >= support_value:\n",
    "            frequent_candidates.append(candidate)\n",
    "            freq_itemsets.append((candidate if is_tuple else tuple({candidate}), 1))\n",
    "    return frequent_candidates\n",
    "\n",
    "\n",
    "def get_frequent_candidate_tuples(frequent_items, size):\n",
    "    candidates = []\n",
    "    for item_x in frequent_items:\n",
    "        for item_y in frequent_items:\n",
    "            combined_set = tuple(sorted(set(item_x + item_y)))\n",
    "            if len(combined_set) == size:\n",
    "                if combined_set not in candidates:\n",
    "                    previous_candidates = list(itertools.combinations(combined_set, size - 1))\n",
    "                    flag = True\n",
    "                    for candidate in previous_candidates:\n",
    "                        if candidate not in frequent_items:\n",
    "                            flag = False\n",
    "                            break\n",
    "                    if flag:\n",
    "                        candidates.append(combined_set)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def get_frequent_candidate_tuples(frequent_items, size):\n",
    "    candidates = []\n",
    "    for item_x in frequent_items:\n",
    "        for item_y in frequent_items:\n",
    "            combined_set = tuple(sorted(set(item_x + item_y)))\n",
    "            if len(combined_set) == size:\n",
    "                if combined_set not in candidates:\n",
    "                    previous_candidates = list(itertools.combinations(combined_set, size - 1))\n",
    "                    flag = True\n",
    "                    for candidate in previous_candidates:\n",
    "                        if candidate not in frequent_items:\n",
    "                            flag = False\n",
    "                            break\n",
    "                    if flag:\n",
    "                        candidates.append(combined_set)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def find_frequent_candidates(chunk, chunk_support, frequent_items, size):\n",
    "    if size == 2:\n",
    "        candidates = list(itertools.combinations(sorted(frequent_items), 2))\n",
    "    else:\n",
    "        candidates = get_frequent_candidate_tuples(frequent_items, size)\n",
    "    return filter_by_support(create_count_dict_tuple(chunk, chunk_support, candidates), chunk_support, True)\n",
    "\n",
    "\n",
    "def apriori(basket):\n",
    "    items = []\n",
    "    \n",
    "    for txn in basket:\n",
    "        for item in txn:\n",
    "            items.append(item)\n",
    "    #frequent itemsets of size 1\n",
    "\n",
    "    frequent_items = filter_by_support(create_count_dict(items, support), support, False)\n",
    "    size = 2\n",
    "    while len(frequent_items) != 0:\n",
    "        frequent_items = find_frequent_candidates(basket, support, frequent_items, size)\n",
    "        size += 1\n",
    "\n",
    "    return freq_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 18 µs, total: 41 µs\n",
      "Wall time: 45.1 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('carrot',), 1),\n",
       " (('banana',), 1),\n",
       " (('edamame',), 1),\n",
       " (('banana', 'edamame'), 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "apriori(basket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dam_proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
