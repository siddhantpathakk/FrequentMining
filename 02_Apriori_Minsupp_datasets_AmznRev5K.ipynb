{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "from apriori_algorithm import AprioriAlgorithm\n",
    "from preprocessor import Streamer, preprocess\n",
    "from colorama import Fore\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = {\n",
    "    'amazon-reviews': {\n",
    "        'path': './data/amazon-reviews/all_csv_files.csv',\n",
    "\n",
    "        # using only half the dataset\n",
    "        'size': 233055326//2,  # original size = 233055326\n",
    "\n",
    "        'limit': 70000,\n",
    "        'minsup': [5000]\n",
    "    },\n",
    "\n",
    "    'groceries': {\n",
    "        'path': './data/groceries/Groceries_dataset.csv',\n",
    "        'size': 38766,\n",
    "        'limit': 10000,\n",
    "        'minsup': [200, 150, 100, 50, 25, 10]\n",
    "    },\n",
    "\n",
    "\n",
    "    'movielens': {\n",
    "        'path': ['./data/movielens/ratings.csv', './data/movielens/movies.csv'],\n",
    "        'size': 100836,\n",
    "        'limit': 50000,\n",
    "        'minsup': [500, 400, 300, 200, 100, 50]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SUPPORT = 100\n",
    "VERBOSE = False\n",
    "DISPLAY_ITERATION = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    # 'groceries',\n",
    "    # 'movielens',\n",
    "    'amazon-reviews',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_rating = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mRunning Apriori on amazon-reviews : streams = 1664 , minsup = 5000\n",
      "\u001b[37m################################################################################\n",
      "\u001b[37m\tAccessing data-stream #0\n",
      "\u001b[32m\tNum. of transactions: 48514\n",
      "\u001b[32m\tNum. of freq itemsets: 1\n",
      "\u001b[37m\tFinished data-stream #0 in 0.58 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #2\n",
      "\u001b[32m\tNum. of transactions: 52371\n",
      "\u001b[32m\tNum. of freq itemsets: 1\n",
      "\u001b[37m\tFinished data-stream #2 in 0.64 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #8\n",
      "\u001b[32m\tNum. of transactions: 46400\n",
      "\u001b[32m\tNum. of freq itemsets: 2\n",
      "\u001b[37m\tFinished data-stream #8 in 0.61 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #9\n",
      "\u001b[32m\tNum. of transactions: 52353\n",
      "\u001b[32m\tNum. of freq itemsets: 3\n",
      "\u001b[37m\tFinished data-stream #9 in 0.75 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #10\n",
      "\u001b[32m\tNum. of transactions: 43044\n",
      "\u001b[32m\tNum. of freq itemsets: 1\n",
      "\u001b[37m\tFinished data-stream #10 in 0.66 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #11\n",
      "\u001b[32m\tNum. of transactions: 52607\n",
      "\u001b[32m\tNum. of freq itemsets: 4\n",
      "\u001b[37m\tFinished data-stream #11 in 0.97 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #12\n",
      "\u001b[32m\tNum. of transactions: 50342\n",
      "\u001b[32m\tNum. of freq itemsets: 3\n",
      "\u001b[37m\tFinished data-stream #12 in 0.88 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #13\n",
      "\u001b[32m\tNum. of transactions: 54023\n",
      "\u001b[32m\tNum. of freq itemsets: 3\n",
      "\u001b[37m\tFinished data-stream #13 in 0.9 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #29\n",
      "\u001b[32m\tNum. of transactions: 52861\n",
      "\u001b[32m\tNum. of freq itemsets: 1\n",
      "\u001b[37m\tFinished data-stream #29 in 1.11 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n",
      "\u001b[37m\tAccessing data-stream #41\n",
      "\u001b[32m\tNum. of transactions: 47530\n",
      "\u001b[32m\tNum. of freq itemsets: 1\n",
      "\u001b[37m\tFinished data-stream #41 in 1.36 seconds.\n",
      "\u001b[37m--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    \n",
    "    results = pd.DataFrame(columns=['item_sets', 'supp_count'])\n",
    "    dataset_meta = dataset_metadata[dataset]\n",
    "    num_streams = dataset_meta['size'] // dataset_meta['limit']\n",
    "    \n",
    "    total_time = 0\n",
    "    total_timer = time.time()\n",
    "    \n",
    "    for minsup in dataset_meta['minsup']:\n",
    "        \n",
    "        apriori = AprioriAlgorithm(minsup= minsup, verbose=VERBOSE)\n",
    "        \n",
    "        if dataset == 'movielens':\n",
    "            datastream = Streamer(filepath=dataset_meta['path'][0],\n",
    "                                stream_limit=dataset_meta['limit'])\n",
    "            movies_df = pd.read_csv(dataset_meta['path'][1])\n",
    "\n",
    "        else:\n",
    "            datastream = Streamer(filepath=dataset_meta['path'],\n",
    "                                stream_limit=dataset_meta['limit'])\n",
    "        \n",
    "        print(Fore.WHITE + f'Running Apriori on {dataset} : streams = {num_streams} , minsup = {minsup}')\n",
    "        print(Fore.WHITE + \"##\"*40)\n",
    "        \n",
    "        for stream_id in range(num_streams):\n",
    "\n",
    "            start_time = time.time()\n",
    "            df = datastream.getCurrentStream(stream_id)\n",
    "\n",
    "            if dataset == 'movielens':\n",
    "                movie_transactions = preprocess(dataset_name=dataset,\n",
    "                                                ratings=df,\n",
    "                                                movies=movies_df,\n",
    "                                                threshold_rating=threshold_rating)\n",
    "\n",
    "            else:\n",
    "                movie_transactions = preprocess(dataset_name=dataset, \n",
    "                                                df=df, \n",
    "                                                threshold_rating=threshold_rating)\n",
    "                \n",
    "        \n",
    "            freq_item_sets = apriori.run(movie_transactions)\n",
    "            \n",
    "            results = pd.concat([results, freq_item_sets], ignore_index=True)\n",
    "            results = results.drop_duplicates()\n",
    "            \n",
    "                \n",
    "            \n",
    "            if len(freq_item_sets) > 0 or VERBOSE or stream_id == 0 or stream_id % DISPLAY_ITERATION == 0:\n",
    "                print(Fore.WHITE + f'\\tAccessing data-stream #{stream_id}')\n",
    "                print(Fore.GREEN + f'\\tNum. of transactions: {len(movie_transactions)}')\n",
    "                print(Fore.GREEN + f'\\tNum. of freq itemsets: {len(freq_item_sets)}')\n",
    "                \n",
    "                time_taken = round(time.time() - start_time, 2)\n",
    "                print(Fore.WHITE + f'\\tFinished data-stream #{stream_id} in {time_taken} seconds.')\n",
    "\n",
    "                print(Fore.WHITE + '--'*40)\n",
    "    \n",
    "        # display(results)\n",
    "        results.to_csv(f'./logs/{dataset}/itemsets_df_minsup_{minsup}.csv', index=False)\n",
    "        \n",
    "    \n",
    "    total_time += time.time() - total_timer\n",
    "    print(Fore.GREEN + f'Completed {dataset} dataset in {total_time:.2f} seconds.')\n",
    "\n",
    "    print(Fore.WHITE + \"##\"*40, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp_spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
