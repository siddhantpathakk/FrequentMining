{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matthew Militante \n",
    "\n",
    "https://github.com/mattmili/DataMining/blob/master/pcy.py\n",
    "\n",
    "This is an implementation of the PCY algorithm to find frequent item sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash(num1, num2):\n",
    "  ''' Hash function for the hash table '''\n",
    "  return (num1 ^ num2) % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bitmap(hash_table, threshold):\n",
    "  ''' Convert the hash table into a bitmap '''\n",
    "  bit_map = []\n",
    "  for key, value in hash_table.items():\n",
    "    if value < threshold:\n",
    "      bit_map.insert(key, 0)\n",
    "    else:\n",
    "      bit_map.insert(key, 1)\n",
    "\n",
    "  return bit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_candidate_item_set(dataset_file):\n",
    "  ''' Create a dictionary of all candidate item sets from the data set with their corresponding count '''\n",
    "  \n",
    "  candidate_item_list = defaultdict(int)\n",
    "  baskets = []\n",
    "\n",
    "  buckets = {}\n",
    "\n",
    "  with open(dataset_file) as file:\n",
    "    for line in file:\n",
    "      ##\n",
    "      # Create the candidate item set\n",
    "      ##\n",
    "      num_list = map(int, line.split())\n",
    "      # create a list of all baskets\n",
    "      baskets.append(num_list)\n",
    "      # create a dictionary with a count of each individual item\n",
    "      for item in num_list:\n",
    "        candidate_item_list[item] += 1\n",
    "\n",
    "      ##\n",
    "      # Create pairs of unique items in each bucket\n",
    "      ##\n",
    "      pairs = list(it.combinations(num_list, 2))\n",
    "      for pair in pairs:\n",
    "        index = hash(pair[0], pair[1]) \n",
    "        buckets[index] = 1 if index not in buckets else buckets[index]+1\n",
    "\n",
    "  return candidate_item_list, baskets, buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequent_item_set(item_list, min_threshold):\n",
    "  ''' Return the frequent items from the candidate_item_list that meet the min_support '''\n",
    "\n",
    "  # delete items that dont meet min threshold\n",
    "  for key, value in item_list.items():\n",
    "    if value < min_threshold:\n",
    "      del item_list[key]\n",
    "\n",
    "  return item_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(item_list, baskets):\n",
    "  ''' Count the number of frequent item sets in the baskets '''\n",
    "  count = dict(zip(item_list, [1]*len(item_list)))\n",
    "\n",
    "  for basket in baskets:\n",
    "    for key in count.keys():\n",
    "      if set(list(key)) < set(basket):\n",
    "        count[key] += 1 \n",
    "\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(freq_item_sets, k):\n",
    "  ''' Generate the joint transactions from candidate sets of size k '''\n",
    "  \n",
    "  # k is the size of each item set\n",
    "  if k <= 2: \n",
    "    return list(it.combinations(freq_item_sets, k))\n",
    "  else:\n",
    "    return list(it.combinations(set(a for b in freq_item_sets for a in b),k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataset_file, threshold):  \n",
    "  \n",
    "  C1, baskets, buckets = create_candidate_item_set(dataset_file)\n",
    "  bitmap = create_bitmap(buckets, threshold)\n",
    "  F1_items = create_frequent_item_set(C1, threshold)\n",
    "\n",
    "  # hash each frequent item into the bitmap and remove non frequent pairs\n",
    "  frequent_pairs = join(F1_items, 2)\n",
    "  for pair in frequent_pairs:\n",
    "    hash_value = hash(pair[0], pair[1])\n",
    "    if bitmap[hash_value] is not 1:\n",
    "      frequent_pairs.remove(pair)\n",
    "\n",
    "  if not frequent_pairs:\n",
    "    return None\n",
    "  else:\n",
    "    # Initialize with possible frequent pairs\n",
    "    L = [frequent_pairs]\n",
    "    items = count(L[0], baskets)\n",
    "    # check which frequent pairs meet minimum threshold value\n",
    "    L[0] = create_frequent_item_set(items, threshold)\n",
    "\n",
    "    k = 3\n",
    "    while(True):\n",
    "      new_list = join(L[k-3], k)\n",
    "      items = count(new_list, baskets)\n",
    "\n",
    "      Fk_items = create_frequent_item_set(items, threshold)\n",
    "      if len(Fk_items) > 0:\n",
    "        L.append(Fk_items)\n",
    "        k+=1\n",
    "      else:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    return L[k-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori(dataset_file='', threshold = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
