╰─ spark-submit task2_groceries.py  
23/11/20 07:11:07 WARN Utils: Your hostname, Siddhant-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.91.3.5 instead (on interface en0)
23/11/20 07:11:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Running SON Apriori Algorithm on groceries with minsup value: 250

23/11/20 07:11:08 INFO SparkContext: Running Spark version 3.5.0
23/11/20 07:11:08 INFO SparkContext: OS info Mac OS X, 14.1, aarch64
23/11/20 07:11:08 INFO SparkContext: Java version 19.0.1
23/11/20 07:11:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/20 07:11:08 INFO ResourceUtils: ==============================================================
23/11/20 07:11:08 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 07:11:08 INFO ResourceUtils: ==============================================================
23/11/20 07:11:08 INFO SparkContext: Submitted application: cz4032_task2
23/11/20 07:11:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 07:11:08 INFO ResourceProfile: Limiting resource is cpu
23/11/20 07:11:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 07:11:08 INFO SecurityManager: Changing view acls to: siddhantpathak
23/11/20 07:11:08 INFO SecurityManager: Changing modify acls to: siddhantpathak
23/11/20 07:11:08 INFO SecurityManager: Changing view acls groups to: 
23/11/20 07:11:08 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 07:11:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: siddhantpathak; groups with view permissions: EMPTY; users with modify permissions: siddhantpathak; groups with modify permissions: EMPTY
23/11/20 07:11:08 INFO Utils: Successfully started service 'sparkDriver' on port 58872.
23/11/20 07:11:08 INFO SparkEnv: Registering MapOutputTracker
23/11/20 07:11:08 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 07:11:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 07:11:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 07:11:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 07:11:08 INFO DiskBlockManager: Created local directory at /private/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/blockmgr-a8e245ae-6706-48a4-85fe-5b61c4ddc040
23/11/20 07:11:08 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 07:11:08 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 07:11:08 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/20 07:11:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/20 07:11:09 INFO Executor: Starting executor ID driver on host 10.91.3.5
23/11/20 07:11:09 INFO Executor: OS info Mac OS X, 14.1, aarch64
23/11/20 07:11:09 INFO Executor: Java version 19.0.1
23/11/20 07:11:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/20 07:11:09 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4bf97dd0 for default.
23/11/20 07:11:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58873.
23/11/20 07:11:09 INFO NettyBlockTransferService: Server created on 10.91.3.5:58873
23/11/20 07:11:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 07:11:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.91.3.5, 58873, None)
23/11/20 07:11:09 INFO BlockManagerMasterEndpoint: Registering block manager 10.91.3.5:58873 with 434.4 MiB RAM, BlockManagerId(driver, 10.91.3.5, 58873, None)
23/11/20 07:11:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.91.3.5, 58873, None)
23/11/20 07:11:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.91.3.5, 58873, None)
------------------------------------------------------------
| MINSUP: 250
| Time taken: 3.4 seconds.
| Outputs saved to ./logs/groceries/groceries_minsup_250.txt.
------------------------------------------------------------

╭─ ~/Desktop/Projects/FrequentMining  on pyspark ⇣2 *3 ~1 +1 !10 ?1                                                                                    ✔  took 5s  fp_spark   
╰─ spark-submit task2_groceries.py 
23/11/20 07:11:52 WARN Utils: Your hostname, Siddhant-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.91.3.5 instead (on interface en0)
23/11/20 07:11:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Running SON Apriori Algorithm on groceries with minsup value: 200

23/11/20 07:11:53 INFO SparkContext: Running Spark version 3.5.0
23/11/20 07:11:53 INFO SparkContext: OS info Mac OS X, 14.1, aarch64
23/11/20 07:11:53 INFO SparkContext: Java version 19.0.1
23/11/20 07:11:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/20 07:11:53 INFO ResourceUtils: ==============================================================
23/11/20 07:11:53 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 07:11:53 INFO ResourceUtils: ==============================================================
23/11/20 07:11:53 INFO SparkContext: Submitted application: cz4032_task2
23/11/20 07:11:53 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 07:11:53 INFO ResourceProfile: Limiting resource is cpu
23/11/20 07:11:53 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 07:11:53 INFO SecurityManager: Changing view acls to: siddhantpathak
23/11/20 07:11:53 INFO SecurityManager: Changing modify acls to: siddhantpathak
23/11/20 07:11:53 INFO SecurityManager: Changing view acls groups to: 
23/11/20 07:11:53 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 07:11:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: siddhantpathak; groups with view permissions: EMPTY; users with modify permissions: siddhantpathak; groups with modify permissions: EMPTY
23/11/20 07:11:53 INFO Utils: Successfully started service 'sparkDriver' on port 58890.
23/11/20 07:11:53 INFO SparkEnv: Registering MapOutputTracker
23/11/20 07:11:53 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 07:11:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 07:11:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 07:11:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 07:11:53 INFO DiskBlockManager: Created local directory at /private/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/blockmgr-706b4478-0b25-46fe-8d81-9a1d6456ce43
23/11/20 07:11:53 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 07:11:53 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 07:11:53 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/20 07:11:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/20 07:11:53 INFO Executor: Starting executor ID driver on host 10.91.3.5
23/11/20 07:11:53 INFO Executor: OS info Mac OS X, 14.1, aarch64
23/11/20 07:11:53 INFO Executor: Java version 19.0.1
23/11/20 07:11:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/20 07:11:53 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@30bd84d3 for default.
23/11/20 07:11:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58891.
23/11/20 07:11:53 INFO NettyBlockTransferService: Server created on 10.91.3.5:58891
23/11/20 07:11:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 07:11:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.91.3.5, 58891, None)
23/11/20 07:11:53 INFO BlockManagerMasterEndpoint: Registering block manager 10.91.3.5:58891 with 434.4 MiB RAM, BlockManagerId(driver, 10.91.3.5, 58891, None)
23/11/20 07:11:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.91.3.5, 58891, None)
23/11/20 07:11:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.91.3.5, 58891, None)
------------------------------------------------------------
| MINSUP: 200
| Time taken: 3.2 seconds.
| Outputs saved to ./logs/groceries/groceries_minsup_200.txt.
------------------------------------------------------------

╭─ ~/Desktop/Projects/FrequentMining  on pyspark ⇣2 *3 ~1 +1 !9 ?1                                                                                     ✔  took 4s  fp_spark   
╰─ spark-submit task2_groceries.py 
23/11/20 07:12:19 WARN Utils: Your hostname, Siddhant-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.91.3.5 instead (on interface en0)
23/11/20 07:12:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Running SON Apriori Algorithm on groceries with minsup value: 150

23/11/20 07:12:19 INFO SparkContext: Running Spark version 3.5.0
23/11/20 07:12:19 INFO SparkContext: OS info Mac OS X, 14.1, aarch64
23/11/20 07:12:19 INFO SparkContext: Java version 19.0.1
23/11/20 07:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/20 07:12:19 INFO ResourceUtils: ==============================================================
23/11/20 07:12:19 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 07:12:19 INFO ResourceUtils: ==============================================================
23/11/20 07:12:19 INFO SparkContext: Submitted application: cz4032_task2
23/11/20 07:12:19 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 07:12:19 INFO ResourceProfile: Limiting resource is cpu
23/11/20 07:12:19 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 07:12:19 INFO SecurityManager: Changing view acls to: siddhantpathak
23/11/20 07:12:19 INFO SecurityManager: Changing modify acls to: siddhantpathak
23/11/20 07:12:19 INFO SecurityManager: Changing view acls groups to: 
23/11/20 07:12:19 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 07:12:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: siddhantpathak; groups with view permissions: EMPTY; users with modify permissions: siddhantpathak; groups with modify permissions: EMPTY
23/11/20 07:12:19 INFO Utils: Successfully started service 'sparkDriver' on port 58922.
23/11/20 07:12:19 INFO SparkEnv: Registering MapOutputTracker
23/11/20 07:12:19 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 07:12:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 07:12:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 07:12:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 07:12:19 INFO DiskBlockManager: Created local directory at /private/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/blockmgr-d9c0e341-e182-46f6-a108-02a486adee2c
23/11/20 07:12:19 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 07:12:19 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 07:12:19 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/20 07:12:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/20 07:12:20 INFO Executor: Starting executor ID driver on host 10.91.3.5
23/11/20 07:12:20 INFO Executor: OS info Mac OS X, 14.1, aarch64
23/11/20 07:12:20 INFO Executor: Java version 19.0.1
23/11/20 07:12:20 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/20 07:12:20 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4bf97dd0 for default.
23/11/20 07:12:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58924.
23/11/20 07:12:20 INFO NettyBlockTransferService: Server created on 10.91.3.5:58924
23/11/20 07:12:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 07:12:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.91.3.5, 58924, None)
23/11/20 07:12:20 INFO BlockManagerMasterEndpoint: Registering block manager 10.91.3.5:58924 with 434.4 MiB RAM, BlockManagerId(driver, 10.91.3.5, 58924, None)
23/11/20 07:12:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.91.3.5, 58924, None)
23/11/20 07:12:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.91.3.5, 58924, None)
------------------------------------------------------------
| MINSUP: 150
| Time taken: 3.4 seconds.
| Outputs saved to ./logs/groceries/groceries_minsup_150.txt.
------------------------------------------------------------

╭─ ~/Desktop/Projects/FrequentMining  on pyspark ⇣2 *3 ~1 +1 !8 ?1                                                                                     ✔  took 5s  fp_spark   
╰─ spark-submit task2_groceries.py 
23/11/20 07:12:44 WARN Utils: Your hostname, Siddhant-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.91.3.5 instead (on interface en0)
23/11/20 07:12:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Running SON Apriori Algorithm on groceries with minsup value: 100

23/11/20 07:12:45 INFO SparkContext: Running Spark version 3.5.0
23/11/20 07:12:45 INFO SparkContext: OS info Mac OS X, 14.1, aarch64
23/11/20 07:12:45 INFO SparkContext: Java version 19.0.1
23/11/20 07:12:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/20 07:12:45 INFO ResourceUtils: ==============================================================
23/11/20 07:12:45 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 07:12:45 INFO ResourceUtils: ==============================================================
23/11/20 07:12:45 INFO SparkContext: Submitted application: cz4032_task2
23/11/20 07:12:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 07:12:45 INFO ResourceProfile: Limiting resource is cpu
23/11/20 07:12:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 07:12:45 INFO SecurityManager: Changing view acls to: siddhantpathak
23/11/20 07:12:45 INFO SecurityManager: Changing modify acls to: siddhantpathak
23/11/20 07:12:45 INFO SecurityManager: Changing view acls groups to: 
23/11/20 07:12:45 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 07:12:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: siddhantpathak; groups with view permissions: EMPTY; users with modify permissions: siddhantpathak; groups with modify permissions: EMPTY
23/11/20 07:12:45 INFO Utils: Successfully started service 'sparkDriver' on port 58947.
23/11/20 07:12:45 INFO SparkEnv: Registering MapOutputTracker
23/11/20 07:12:45 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 07:12:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 07:12:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 07:12:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 07:12:45 INFO DiskBlockManager: Created local directory at /private/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/blockmgr-e22adbf8-0286-4cc0-adb8-d3a1c41621e7
23/11/20 07:12:45 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 07:12:45 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 07:12:45 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/20 07:12:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/20 07:12:45 INFO Executor: Starting executor ID driver on host 10.91.3.5
23/11/20 07:12:45 INFO Executor: OS info Mac OS X, 14.1, aarch64
23/11/20 07:12:45 INFO Executor: Java version 19.0.1
23/11/20 07:12:45 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/20 07:12:45 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4bf97dd0 for default.
23/11/20 07:12:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58948.
23/11/20 07:12:45 INFO NettyBlockTransferService: Server created on 10.91.3.5:58948
23/11/20 07:12:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 07:12:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.91.3.5, 58948, None)
23/11/20 07:12:45 INFO BlockManagerMasterEndpoint: Registering block manager 10.91.3.5:58948 with 434.4 MiB RAM, BlockManagerId(driver, 10.91.3.5, 58948, None)
23/11/20 07:12:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.91.3.5, 58948, None)
23/11/20 07:12:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.91.3.5, 58948, None)
------------------------------------------------------------
| MINSUP: 100
| Time taken: 4.1 seconds.
| Outputs saved to ./logs/groceries/groceries_minsup_100.txt.
------------------------------------------------------------

╭─ ~/Desktop/Projects/FrequentMining  on pyspark ⇣2 *3 ~1 +1 !7 ?1                                                                                     ✔  took 5s  fp_spark   
╰─ spark-submit task2_groceries.py 
23/11/20 07:13:08 WARN Utils: Your hostname, Siddhant-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.91.3.5 instead (on interface en0)
23/11/20 07:13:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Running SON Apriori Algorithm on groceries with minsup value: 50

23/11/20 07:13:08 INFO SparkContext: Running Spark version 3.5.0
23/11/20 07:13:08 INFO SparkContext: OS info Mac OS X, 14.1, aarch64
23/11/20 07:13:08 INFO SparkContext: Java version 19.0.1
23/11/20 07:13:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/20 07:13:08 INFO ResourceUtils: ==============================================================
23/11/20 07:13:08 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/20 07:13:08 INFO ResourceUtils: ==============================================================
23/11/20 07:13:08 INFO SparkContext: Submitted application: cz4032_task2
23/11/20 07:13:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/20 07:13:08 INFO ResourceProfile: Limiting resource is cpu
23/11/20 07:13:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/20 07:13:08 INFO SecurityManager: Changing view acls to: siddhantpathak
23/11/20 07:13:08 INFO SecurityManager: Changing modify acls to: siddhantpathak
23/11/20 07:13:08 INFO SecurityManager: Changing view acls groups to: 
23/11/20 07:13:08 INFO SecurityManager: Changing modify acls groups to: 
23/11/20 07:13:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: siddhantpathak; groups with view permissions: EMPTY; users with modify permissions: siddhantpathak; groups with modify permissions: EMPTY
23/11/20 07:13:08 INFO Utils: Successfully started service 'sparkDriver' on port 58966.
23/11/20 07:13:08 INFO SparkEnv: Registering MapOutputTracker
23/11/20 07:13:08 INFO SparkEnv: Registering BlockManagerMaster
23/11/20 07:13:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/20 07:13:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/20 07:13:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/20 07:13:09 INFO DiskBlockManager: Created local directory at /private/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/blockmgr-2b100fcb-f99c-4b69-b711-27562aeb3fed
23/11/20 07:13:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/20 07:13:09 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/20 07:13:09 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/20 07:13:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/20 07:13:09 INFO Executor: Starting executor ID driver on host 10.91.3.5
23/11/20 07:13:09 INFO Executor: OS info Mac OS X, 14.1, aarch64
23/11/20 07:13:09 INFO Executor: Java version 19.0.1
23/11/20 07:13:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/20 07:13:09 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4bf97dd0 for default.
23/11/20 07:13:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58967.
23/11/20 07:13:09 INFO NettyBlockTransferService: Server created on 10.91.3.5:58967
23/11/20 07:13:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/20 07:13:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.91.3.5, 58967, None)
23/11/20 07:13:09 INFO BlockManagerMasterEndpoint: Registering block manager 10.91.3.5:58967 with 434.4 MiB RAM, BlockManagerId(driver, 10.91.3.5, 58967, None)
23/11/20 07:13:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.91.3.5, 58967, None)
23/11/20 07:13:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.91.3.5, 58967, None)
------------------------------------------------------------
| MINSUP: 50
| Time taken: 11.2 seconds.
| Outputs saved to ./logs/groceries/groceries_minsup_50.txt.
------------------------------------------------------------

╭─ ~/Desktop/Projects/FrequentMining  on pyspark ⇣2 *3 ~1 +1 !7 ?1                                                                                    ✔  took 12s  fp_spark   
╰─      